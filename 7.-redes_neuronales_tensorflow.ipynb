{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sherna90/inteligencia_artificial/blob/master/7.-redes_neuronales_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOwWhYDRHNGW"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FP5258xjs-v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "X=np.array([[1,0.5],[1.5,1],[0.5,1],[1,1.5]])\n",
        "y=np.array([0,0,1,1]).T\n",
        "plt.scatter(X[0:2,0],X[0:2,1],marker='o',c='k')\n",
        "plt.scatter(X[2:4,0],X[2:4,1],marker='x',c='b')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLgVhZ8CTUOW"
      },
      "source": [
        "\\begin{align*}J(\\theta)=-\\frac{1}{m}\\sum_{i=1}^{m}y^{i}\\log(h_\\theta(x^{i}))+(1-y^{i})\\log(1-h_\\theta(x^{i}))\\end{align*}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_khQ8_zRfyMC"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1.0/(1.0+np.exp(-x))\n",
        "\n",
        "def logistic_predictions(weights, inputs):\n",
        "    # Outputs probability of a label being true according to logistic model.\n",
        "    return sigmoid(np.matmul(inputs, weights))\n",
        "\n",
        "def training_loss(inputs,targets,weights):\n",
        "    # Training loss is the negative log-likelihood of the training labels.\n",
        "    preds = logistic_predictions(weights, inputs)\n",
        "    label_probabilities = np.log(preds) * targets + np.log(1 - preds) * (1 - targets)\n",
        "    return -np.mean(label_probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu9Otn8ySlvz"
      },
      "source": [
        "\\begin{align*}\n",
        "\\frac{\\partial }{\\partial \\theta_j} L(\\theta) &= -\\frac{1}{m}\\sum\\limits_{i=1}^{m}{y_i.\\frac{\\partial }{\\partial \\theta_j} log P(y_i|x_i,\\theta)   + (1-y_i).\\frac{\\partial }{\\partial \\theta_j} \\log{(1 - P(y_i|x_i,\\theta))}} \\\\\n",
        "&=-\\frac{1}{m}\\sum\\limits_{i=1}^{m}{y_i.x_i^j.\\left(1-P(y_i|x_i,\\theta)\\right) - (1-y_i).x_i^j.P(y_i|x_i,\\theta)} \\\\\n",
        "&=-\\frac{1}{m}\\sum\\limits_{i=1}^{m}{y_i.x_i^j - x_i^j.P(y_i|x_i,\\theta)} \\\\\n",
        "&=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{(P(y_i|x_i,\\theta)-y_i).x_i^j}\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TDac4p_JV5f"
      },
      "outputs": [],
      "source": [
        "def log_sigmoid_derivative(x):\n",
        "  return 1.0/(1.0+np.exp(x))\n",
        "\n",
        "def training_loss_derivative(inputs,targets,weights):\n",
        "  preds = logistic_predictions(weights, inputs)\n",
        "  return np.mean((preds-targets.reshape((-1,1)))*inputs,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-aatMJ2RCW0"
      },
      "outputs": [],
      "source": [
        "w=np.random.normal(0,1,2).reshape((-1,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97Hd3w4kQxol"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc7aprYuLpmd"
      },
      "outputs": [],
      "source": [
        "training_loss_derivative(X,y,w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MUELYVDw-8r"
      },
      "source": [
        "https://math.stackexchange.com/questions/2320905/obtaining-derivative-of-log-of-sigmoid-function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_5b4ac-JOb4"
      },
      "outputs": [],
      "source": [
        "loss_val=list()\n",
        "for i in range(3000):\n",
        "    w -= training_loss_derivative(X,y,w).reshape((-1,1)) * 0.01\n",
        "    loss_val.append(training_loss(X,y,w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kttIzExRstBh"
      },
      "outputs": [],
      "source": [
        "plt.plot(loss_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvajNhDcQ6Gu"
      },
      "outputs": [],
      "source": [
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "h = 0.01\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBG3JYM9UZv5"
      },
      "outputs": [],
      "source": [
        "Z=logistic_predictions(w,np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpzCaEbhMNVi"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.Blues)\n",
        "plt.scatter(X[0:2,0],X[0:2,1],marker='o',c='w')\n",
        "plt.scatter(X[2:4,0],X[2:4,1],marker='x',c='b')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGotU62g-7LS"
      },
      "source": [
        "# Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE2FgPSF-9Jh"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = make_moons(n_samples=5000,shuffle=True,noise=0.3)\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uKrOwcq_DYx"
      },
      "outputs": [],
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, alpha=0.6)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "\n",
        "tensorflow.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "0fAbq2KO0fgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWtwmW3X_kmH"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,Input\n",
        "from tensorflow.keras.optimizers import RMSprop,SGD\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(2))\n",
        "model.add(Dense(64,activation='relu',kernel_regularizer=regularizers.L2(0.01)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(32,activation='relu',kernel_regularizer=regularizers.L2(0.01)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "32*64+32"
      ],
      "metadata": {
        "id": "-j8KHqRC4g9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64\n",
        "\n",
        "X_train.shape[0]/batch_size"
      ],
      "metadata": {
        "id": "88-QQRQwyJ2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnRX_n0e_66a"
      },
      "outputs": [],
      "source": [
        "epochs=300\n",
        "opt = SGD(1e-3,momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train,epochs=epochs, verbose=1,batch_size=batch_size)\n",
        "score = model.evaluate(X_test, y_test, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbYib2q5B66I"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"accuracy\"])"
      ],
      "metadata": {
        "id": "tPGc3JIe2u8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flIL4Tc8AikY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred=model.predict(X_test)\n",
        "print(classification_report(y_test, np.int32(y_pred>0.5)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTvo7B1qstBj"
      },
      "outputs": [],
      "source": [
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "h = 0.01\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "Z=model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxQ378lLAs3p"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.Blues)\n",
        "plt.scatter(X_test[:,0],X_test[:,1],c=y_test,alpha=.5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur0rrELcfyMk"
      },
      "source": [
        "# Redes Neuronales Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEZaPVQlfyMk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,Flatten\n",
        "from tensorflow.keras.optimizers import RMSprop,SGD\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train=x_train.reshape((-1,784))\n",
        "x_test=x_test.reshape((-1,784))\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[2,:].reshape((28,28))),np.argmax(y_train[2])"
      ],
      "metadata": {
        "id": "Zx17Z49H6Tvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ULgMNK9fyMn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(784))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlifK1c9VPBC"
      },
      "outputs": [],
      "source": [
        "784*128+128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sxfEd4CVBoN"
      },
      "outputs": [],
      "source": [
        "epochs=100\n",
        "sgd = SGD(lr=0.01, decay=0, momentum=0.9)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAn_qfLYfyMq"
      },
      "outputs": [],
      "source": [
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6kJqNBUfyMu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "N = np.arange(0, epochs)\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "fig = plt.figure(figsize=(15,7))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(N, history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Train/Val Loss (Simple NN)\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(N, history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(N, history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Train/Val Accuracy (Simple NN)\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlPoxwxfYavf"
      },
      "outputs": [],
      "source": [
        "y_pred=model.predict(x_test)\n",
        "print(classification_report(np.argmax(y_test,axis=1), np.argmax(y_pred,axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfO-UGj6YvKl"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ4g7FBMfyM5"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        Conv2D(32, kernel_size=(3, 3), activation=\"relu\",padding=\"same\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, kernel_size=(3, 3), activation=\"relu\",padding=\"same\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MExSljZQcFw6"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_XGYPG0dVN4"
      },
      "outputs": [],
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuinLiu4cmhJ"
      },
      "outputs": [],
      "source": [
        "y_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMvRiZyodcJ2"
      },
      "outputs": [],
      "source": [
        "def log_loss(y_pred,y_true):\n",
        "  return -1.0*np.mean(y_true*np.log(y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYaXhqHldzLm"
      },
      "outputs": [],
      "source": [
        "theta=np.random.beta(1,1,size=y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQ2LrZjieD99"
      },
      "outputs": [],
      "source": [
        "prob=theta/np.repeat(np.sum(theta,axis=1),repeats=10).reshape(theta.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHlsuJtgevJ5"
      },
      "outputs": [],
      "source": [
        "log_loss(prob,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Cai20UNcVIB"
      },
      "outputs": [],
      "source": [
        "x_train=np.expand_dims(x_train,3)\n",
        "x_test=np.expand_dims(x_test,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSwxtUrecvSo"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir9eCk0xcEoD"
      },
      "outputs": [],
      "source": [
        "epochs=100\n",
        "sgd = SGD(lr=0.01, decay=0, momentum=0.9)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksx6avHOhK5A"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "N = np.arange(0, epochs)\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "fig = plt.figure(figsize=(15,7))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(N, history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Train/Val Loss (Convolutional NN)\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(N, history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(N, history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Train/Val Accuracy (Convolutional NN)\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "naive_bayes_ejemplo.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "3128efba0f908c70094e7aa90436dec83f0168419e3be402a59f10664f1e5468"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}