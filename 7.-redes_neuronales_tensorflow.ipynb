{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive_bayes_ejemplo.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sherna90/inteligencia_artificial/blob/master/7.-redes_neuronales_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOwWhYDRHNGW"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FP5258xjs-v"
      },
      "source": [
        "import numpy as np\n",
        "import random \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Training data\n",
        "X = np.linspace(0,11,num=100)\n",
        "#y = np.asarray([6*x**2 + 8*x + 2 for x in X]) # y = 6x^2 + 8x + 2\n",
        "y=np.asarray([np.sin(x)+np.random.normal(0,0.2) for x in X]) # y = 6x^2 + 8x + 2\n",
        "\n",
        "plt.plot(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_khQ8_zRfyMC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWTxSGGPfyMF"
      },
      "source": [
        "len(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9sZhmpofyMJ"
      },
      "source": [
        "plt.scatter(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxW_HQPJfyMN"
      },
      "source": [
        "plt.scatter(X_test,y_test,c='blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmnEnEOUDmSW"
      },
      "source": [
        "theta=[tf.Variable(np.random.normal(0,0.1), trainable=True,dtype=tf.float64) for i in range(20)]\n",
        "pred_y=tf.math.polyval(theta, X_train)\n",
        "plt.scatter(X_train,y_train,c='blue')\n",
        "plt.scatter(X_train,pred_y,c='red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCMPlbjCfyMQ"
      },
      "source": [
        "# Trainable variables\n",
        "theta=[tf.Variable(np.random.normal(0,0.1), trainable=True,dtype=tf.float64) for i in range(8)]\n",
        "# Loss function\n",
        "\n",
        "def loss(real_y, pred_y,theta):\n",
        "    return tf.reduce_mean(tf.sqrt((real_y - pred_y)**2))\n",
        "\n",
        "# Step function\n",
        "def step(real_x, real_y):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        # Make prediction\n",
        "        pred_y=tf.math.polyval(theta, real_x)\n",
        "        # Calculate loss\n",
        "        poly_loss = loss(real_y, pred_y,theta)\n",
        "    \n",
        "    # Calculate gradients\n",
        "    grads = tape.gradient(poly_loss, theta)\n",
        "    # Update variables\n",
        "    for par,grad in zip(theta,grads):\n",
        "        par.assign_sub(grad * 0.001)\n",
        "    return poly_loss.numpy()\n",
        "\n",
        "# Training loop\n",
        "for i in range(10000):\n",
        "    iter_loss=step(X_train, y_train)\n",
        "    if i%1000==0:\n",
        "        print('iteration : {0}, loss : {1} '.format(i,iter_loss))\n",
        "print('------------------------------------')\n",
        "print(f'y ≈ {theta[0].numpy()}x^2 + {theta[1].numpy()}x + {theta[2].numpy()}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzl6NABpfyMU"
      },
      "source": [
        "La solucion del problema de estimacion de coeficientes puede ser calculada en forma cerrada mediante minimos cuadrados (https://mathworld.wolfram.com/LeastSquaresFittingPolynomial.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da-dyQzdfyMX"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "X_mat = np.flip(PolynomialFeatures(degree=8).fit_transform(X_train.reshape(-1,1)).transpose(),0)\n",
        "inv_mat=np.linalg.inv(np.matmul(X_mat,X_mat.T))\n",
        "theta_hat=np.matmul(inv_mat,np.matmul(X_mat,y_train))\n",
        "print('y ≈ {0:0.2f}x^2 + {1:0.2f}x + {2:0.2f}'.format(*theta_hat.tolist()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MUELYVDw-8r"
      },
      "source": [
        "Podemos utlizar los coeficientes obtenidos mediante minimos cuadrados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZM3aX_2nWmX"
      },
      "source": [
        "y_pred_exact=[]\n",
        "for x in X_test:\n",
        "    y_hat=np.polyval(theta_hat,x)\n",
        "    y_pred_exact.append(y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4Y-aPZRxNNA"
      },
      "source": [
        "Se compara con las predicciones obtenidas mediante descenso del gradiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1w0OeDcfyMa"
      },
      "source": [
        "y_pred=[]\n",
        "for x in X_test:\n",
        "  y_hat=tf.math.polyval(theta, x)\n",
        "  y_pred.append(y_hat.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajs_S5bJfyMh"
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(X_test,y_pred_exact,c='green')\n",
        "plt.scatter(X_test,y_test,c='red',alpha=.5)\n",
        "plt.title('forma cerrada')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_test,y_pred,c='blue')\n",
        "plt.scatter(X_test,y_test,c='red',alpha=.5)\n",
        "plt.title('descenso del gradiente')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqUEfJMd5sQo"
      },
      "source": [
        "El método del descenso del gradiente es numericamente inestable cuando crece el orden del polinomio. Por lo tanto, se necesitan mecanismos de regularización o bien mecanismos de optimización más robustos (Nesterov)\n",
        "\n",
        "https://stats.stackexchange.com/questions/350130/why-is-gradient-descent-so-bad-at-optimizing-polynomial-regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWtwmW3X_kmH"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,Input\n",
        "from tensorflow.keras.optimizers import RMSprop,SGD\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(1))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1,activation='linear'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnRX_n0e_66a"
      },
      "source": [
        "epochs=5000\n",
        "opt = RMSprop(1e-3)\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer=opt,\n",
        "              metrics=['mean_squared_error'])\n",
        "history = model.fit(X_train, y_train,epochs=epochs, verbose=0)\n",
        "score = model.evaluate(X_test, y_test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbYib2q5B66I"
      },
      "source": [
        "plt.plot(history.history[\"loss\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flIL4Tc8AikY"
      },
      "source": [
        "y_pred=model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxQ378lLAs3p"
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(X_test,y_pred_exact,c='green')\n",
        "plt.scatter(X_test,y_test,c='red',alpha=.5)\n",
        "plt.title('forma cerrada')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_test,y_pred,c='blue')\n",
        "plt.scatter(X_test,y_test,c='red',alpha=.5)\n",
        "plt.title('descenso del gradiente keras')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur0rrELcfyMk"
      },
      "source": [
        "# Redes Neuronales Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEZaPVQlfyMk"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,Flatten\n",
        "from tensorflow.keras.optimizers import RMSprop,SGD\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train=x_train.reshape((-1,784))\n",
        "x_test=x_test.reshape((-1,784))\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ULgMNK9fyMn"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(784))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlifK1c9VPBC"
      },
      "source": [
        "784*10+10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sxfEd4CVBoN"
      },
      "source": [
        "epochs=100\n",
        "sgd = SGD(lr=0.01, decay=0, momentum=0.9)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAn_qfLYfyMq"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6kJqNBUfyMu"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "N = np.arange(0, epochs)\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "fig = plt.figure(figsize=(15,7))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(N, history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Train/Val Loss (Simple NN)\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(N, history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(N, history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Train/Val Accuracy (Simple NN)\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlPoxwxfYavf"
      },
      "source": [
        "print(input_shape)\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfO-UGj6YvKl"
      },
      "source": [
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ4g7FBMfyM5"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        Conv2D(32, kernel_size=(3, 3), activation=\"relu\",padding=\"same\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, kernel_size=(3, 3), activation=\"relu\",padding=\"same\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MExSljZQcFw6"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_XGYPG0dVN4"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuinLiu4cmhJ"
      },
      "source": [
        "y_train.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMvRiZyodcJ2"
      },
      "source": [
        "def log_loss(y_pred,y_true):\n",
        "  return -1.0*np.mean(y_true*np.log(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYaXhqHldzLm"
      },
      "source": [
        "theta=np.random.beta(1,1,size=y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ2LrZjieD99"
      },
      "source": [
        "prob=theta/np.repeat(np.sum(theta,axis=1),repeats=10).reshape(theta.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHlsuJtgevJ5"
      },
      "source": [
        "log_loss(prob,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cai20UNcVIB"
      },
      "source": [
        "x_train=np.expand_dims(x_train,3)\n",
        "x_test=np.expand_dims(x_test,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSwxtUrecvSo"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir9eCk0xcEoD"
      },
      "source": [
        "epochs=100\n",
        "sgd = SGD(lr=0.01, decay=0, momentum=0.9)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksx6avHOhK5A"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "N = np.arange(0, epochs)\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "fig = plt.figure(figsize=(15,7))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(N, history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Train/Val Loss (Convolutional NN)\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(N, history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(N, history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Train/Val Accuracy (Convolutional NN)\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}