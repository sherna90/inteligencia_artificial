{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive_bayes_ejemplo.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sherna90/inteligencia_artificial/blob/master/8-naive_bayes_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1piXWeE0AWh7"
      },
      "source": [
        "# Naive Bayes Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOwWhYDRHNGW",
        "scrolled": true
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "Carga y prepara los datos [MNIST dataset](http://yann.lecun.com/exdb/mnist/). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FP5258xjs-v"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "#x_train=x_train.reshape((-1,784))\n",
        "#x_test=x_test.reshape((-1,784))\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAwrNWnKEgDv"
      },
      "source": [
        "x_train=x_train.reshape((-1,784))\n",
        "x_test=x_test.reshape((-1,784))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4mEL65on-w"
      },
      "source": [
        "Entrena un modelo generativo multinomial:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34N5ON0vihQv"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
        "\n",
        "mnb = MultinomialNB(alpha=1.0)\n",
        "y_pred_naive_multinomial = mnb.fit(x_train, y_train).predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBf8yYdLt6RJ"
      },
      "source": [
        "mnb.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhNumS9FAWh_"
      },
      "source": [
        "Entrena un modelo generativo gaussiano:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6hEHPecFyBx"
      },
      "source": [
        "from sklearn import preprocessing \n",
        "\n",
        "scaler=preprocessing.StandardScaler()\n",
        "x_train_normalized = scaler.fit_transform(x_train)\n",
        "x_test_normalized= scaler.transform(x_test)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "y_pred_naive_gaussian = gnb.fit(x_train_normalized, y_train).predict(x_test_normalized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb5yzfS5tLJn"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "ax1 = plt.subplot(2, 2, 1)\n",
        "ax2 = plt.subplot(2, 2, 2)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_naive_multinomial,normalize='pred')\n",
        "ConfusionMatrixDisplay(cm,display_labels=mnb.classes_).plot(ax=ax1)\n",
        "ax1.set_title('Multinomial Naive Bayes')\n",
        "\n",
        "cmg = confusion_matrix(y_test, y_pred_naive_gaussian,normalize='pred')\n",
        "ConfusionMatrixDisplay(cmg,display_labels=gnb.classes_).plot(ax=ax2)\n",
        "ax2.set_title('Gaussian Naive Bayes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHyaXP-qAWiC"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_naive_multinomial))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKHztOPfAWiC"
      },
      "source": [
        "print(classification_report(y_test, y_pred_naive_gaussian))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3xVJGWoK1-K"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x_train_normalized = (x_train>128).astype(np.int)\n",
        "x_test_normalized=  (x_test>128).astype(np.int)\n",
        "\n",
        "bnb = BernoulliNB(alpha=1.0)\n",
        "y_pred_naive_bernoulli = bnb.fit(x_train_normalized, y_train).predict(x_test_normalized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4QOomjWLPQV"
      },
      "source": [
        "print(classification_report(y_test, y_pred_naive_bernoulli))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXVORud3AWiC"
      },
      "source": [
        "# Naive Bayes  Tensorflow Probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfqi6L6IAWiD"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow.keras as keras\n",
        "tfd = tfp.distributions\n",
        "\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train=x_train.reshape((-1,784))\n",
        "x_test=x_test.reshape((-1,784))\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoMyqgFoAWiD"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMdYwJisAWiE"
      },
      "source": [
        "x_train_binary=(x_train>128).astype(np.int)\n",
        "x_test_binary=(x_test>128).astype(np.int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ibsbrwAWiE"
      },
      "source": [
        "def get_prior(y):\n",
        "    probs=[np.sum(y==c_k)/len(y) for c_k in np.unique(y)]\n",
        "    print('The class priors are {}'.format(np.sum(probs)))\n",
        "    priors=tfd.Categorical(probs=probs)\n",
        "    return priors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9R41DHYAWiE"
      },
      "source": [
        "prior=get_prior(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXk9j9uiAWiF"
      },
      "source": [
        "prior.probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czyWyjY7AWiF"
      },
      "source": [
        "labels=np.unique(y_train)\n",
        "plt.bar(range(10), prior.probs.numpy())\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Prior probability\")\n",
        "plt.title(\"Class prior distribution\")\n",
        "plt.xticks(range(10), labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5J-67P8AWiF"
      },
      "source": [
        "Los datos originales de las imagenes contienen regiones donde siempre los valores son cero. Una forma de suavizar la estimacion de probabilidades condicionales es usar suavizado de Laplace (https://en.wikipedia.org/wiki/Additive_smoothing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t-cEJfeAWiF"
      },
      "source": [
        "def laplace_smoothing(binary_data,labels,alpha=1):\n",
        "    n_pixels=binary_data.shape[1]\n",
        "    n_classes=len(np.unique(labels))\n",
        "    theta = np.zeros([n_classes, n_pixels])\n",
        "    for c_k in range(n_classes):\n",
        "        class_mask = (labels == c_k)\n",
        "        N = class_mask.sum() # number of pixels in class\n",
        "        theta[c_k, :] = (binary_data[class_mask, :].sum(axis=0) + alpha)/(N + alpha*2)\n",
        "    return theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD3GMtMDAWiG"
      },
      "source": [
        "theta=laplace_smoothing(x_train_binary,y_train,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbNGDM13AWiG"
      },
      "source": [
        "plt.imshow(theta[0].reshape((28,28)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxG4RdigAWiG"
      },
      "source": [
        "plt.imshow(theta[1].reshape((28,28)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOW7U6FnAWiG"
      },
      "source": [
        "plt.imshow(theta[7].reshape((28,28)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLwe7LcpAWiH"
      },
      "source": [
        "def get_class_conditionals(probs):\n",
        "    class_conditionals=tfd.Bernoulli(probs=probs)\n",
        "    return class_conditionals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvhmci7fAWiH"
      },
      "source": [
        "class_conditionals=get_class_conditionals(theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLx4WrF5AWiH"
      },
      "source": [
        "class_conditionals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTYCHxl5AWiH"
      },
      "source": [
        "digits_sample=class_conditionals.sample(1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBPEMK5SAWiI"
      },
      "source": [
        "rows=4\n",
        "cols=3\n",
        "titles = ['digit 0','digit 1', 'digit 2',\n",
        "         'digit 3','digit 4', 'digit 5',\n",
        "         'digit 6','digit 7', 'digit 8',\n",
        "         'digit 9']\n",
        "axes=[]\n",
        "fig=plt.figure(figsize=(8,8))\n",
        "for i in range(len(titles)):\n",
        "    mv_samples = digits_sample[:,i,:] #take the ith batch [samples x event_shape]\n",
        "    axes.append( fig.add_subplot(rows, cols, i+1) )\n",
        "    subplot_title=(titles[i])\n",
        "    axes[-1].set_title(subplot_title)  \n",
        "    plt.imshow(mv_samples.reshape([28,28]), cmap='Greys')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_xbuIA6AWiI"
      },
      "source": [
        "def predict_sample(prior, class_conditionals, sample):\n",
        "    cond_probs = class_conditionals.log_prob(sample)\n",
        "    prior_probs=tf.cast(prior.logits_parameter(),cond_probs.dtype)\n",
        "    joint_likelihood = tf.add(prior_probs, tf.reduce_sum(cond_probs,axis=1))\n",
        "    norm_factor = tf.math.reduce_logsumexp(joint_likelihood, axis=-1, keepdims=True)\n",
        "    log_prob = joint_likelihood - norm_factor\n",
        "    return tf.math.exp(log_prob).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcXckpHtAWiI"
      },
      "source": [
        "prob=predict_sample(prior,class_conditionals,x_test_binary[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5CCzuO1AWiJ"
      },
      "source": [
        "prob.argmax()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4wmx3ljAWiJ"
      },
      "source": [
        "y_test[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtR-f-z8AWiJ"
      },
      "source": [
        "def predict_class(prior, class_conditionals, x):\n",
        "    pred=[]\n",
        "    for sample in x:\n",
        "        prob=predict_sample(prior, class_conditionals,sample)\n",
        "        pred.append(prob.argmax())\n",
        "    return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6kbQTpMAWiJ"
      },
      "source": [
        "y_pred_tfp=predict_class(prior, class_conditionals, x_test_binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAgMkHRqAWiJ"
      },
      "source": [
        "print(classification_report(y_test, y_pred_tfp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL67TMrPAWiL"
      },
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "cm_tfp = confusion_matrix(y_test, y_pred_tfp,normalize='pred')\n",
        "ConfusionMatrixDisplay(cm_tfp,display_labels=np.unique(y_train)).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mk2E68q1YD5"
      },
      "source": [
        "# https://jaketae.github.io/study/bayes-multi-bandit/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4XlmPKH_IrT"
      },
      "source": [
        "def get_betabernoulli_class_conditionals(binary_data,labels,alpha=1,beta=1):\n",
        "    n_pixels=binary_data.shape[1]\n",
        "    n_classes=len(np.unique(labels))\n",
        "    alpha_posterior = np.zeros([n_classes, n_pixels])\n",
        "    beta_posterior = np.zeros([n_classes, n_pixels])\n",
        "    for c_k in range(n_classes):\n",
        "        class_mask = (labels == c_k)\n",
        "        N = class_mask.sum() # number of pixels in class\n",
        "        y=binary_data[class_mask, :].sum(axis=0)\n",
        "        alpha_posterior[c_k, :] = (alpha+y)\n",
        "        beta_posterior[c_k, :] = (beta+N-y)\n",
        "    probs=tfd.Beta(alpha_posterior,beta_posterior)\n",
        "    class_conditionals=tfd.Bernoulli(probs=probs.mode())\n",
        "    return class_conditionals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nftFmJ0GRWG"
      },
      "source": [
        "class_conditionals_beta=get_betabernoulli_class_conditionals(x_train_binary,y_train,alpha=1,beta=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItbOICdSGqgE"
      },
      "source": [
        "digits_sample=class_conditionals_beta.sample(1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF84wJEUGzym"
      },
      "source": [
        "rows=4\n",
        "cols=3\n",
        "titles = ['digit 0','digit 1', 'digit 2',\n",
        "         'digit 3','digit 4', 'digit 5',\n",
        "         'digit 6','digit 7', 'digit 8',\n",
        "         'digit 9']\n",
        "axes=[]\n",
        "fig=plt.figure(figsize=(8,8))\n",
        "for i in range(len(titles)):\n",
        "    mv_samples = digits_sample[:,i,:] #take the ith batch [samples x event_shape]\n",
        "    axes.append( fig.add_subplot(rows, cols, i+1) )\n",
        "    subplot_title=(titles[i])\n",
        "    axes[-1].set_title(subplot_title)  \n",
        "    plt.imshow(mv_samples.reshape([28,28]), cmap='Greys')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5O46NpRI-tP"
      },
      "source": [
        "# https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE"
      ]
    }
  ]
}